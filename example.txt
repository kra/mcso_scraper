To set up and run on a current vanilla mumblemumble Ubuntu box:

This setup assumes you want to scrape daily, and the scraper will complete
daily.  A real scheduler like supervisord is safer, but probably unecessary.

apt-get install python-dev (yum install python-devel)
apt-get install libxml2-dev libxslt-dev 
  (yum install libxml2-devel libxslt-devel)
(on centos, install sudo, gcc, pyOpenSSL, openssl-devel, epel, python-pip,
    pip install virtualenv)
cd /opt/mhap
git clone git clone git@github.com:kra/mcso_scraper.git
cd mcso_scraper
virtualenv env
source env/bin/activate
# prereqs for scrapy
pip install twisted
pip install w3lib
pip install lxml
pip install scrapy
pip install flask
pip install flask-login
pip install py-bcrypt
scripts/setup.sh boot
# hackish workaround for using nobody instead of a dedicated user
find data -exec chown nobody {} \;
## open up port 80 on iptables
#iptables -A INPUT -p tcp --dport 80 -j ACCEPT
#/etc/init.d/iptables save
#/etc/init.d/iptables restart

/opt/mhap/mcso_scraper/run.sh (executable):

#!/bin/bash
DIR=`dirname $0`
cd $DIR && source env/bin/activate && scrapy crawl mcso

/opt/mhap/mcso_scraper/run_viewer.sh (executable):

#!/bin/bash
DIR=`dirname $0`
cd $DIR && source env/bin/activate && env PYTHONPATH=. view/server.py

/etc/cron.daily/mcso_scraper (executable):

#!/bin/bash
sudo -u nobody /opt/mhap/mcso_scraper/run.sh >>/var/log/mcso_scraper.log 2>>/var/log/mcso_scraper.log

/etc/logrotate.d/mcso_scraper:

/var/log/mcso_scraper.log {
	weekly
	missingok
	rotate 52
	notifempty
	create 640 nobody adm
	sharedscripts
}

/etc/init.d/mcso_viewer:

# XXX a real init script that does this with start/stop

#!/bin/bash
cd /opt/mhap/mcso_scraper
sudo -u nobody /opt/mhap/mcso_scraper/run_viewer.sh
